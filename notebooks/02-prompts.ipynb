{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d123587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cba85",
   "metadata": {},
   "source": [
    "### 1- Prompt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afa8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Tell me a joke about {object}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8de84",
   "metadata": {},
   "source": [
    "### 2- Prompt-LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c1d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65294f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did Donald Trump take his economics textbook to the bar?\\n\\nHe heard they had two-for-one debates on supply and demand!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 13, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BpY5deEmE6JLE7P7BQHrvYmcTxMbz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e473a999-46a5-4497-a0e7-8770d8476137-0', usage_metadata={'input_tokens': 13, 'output_tokens': 25, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"object\": \"Trump\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2dde5",
   "metadata": {},
   "source": [
    "### 3- StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88f7c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Joe Biden bring a pencil to his debate with Trump?\\n\\nIn case he needed to draw a blank!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"object\": \"Joe Biden\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600985a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did Joe Biden bring a ladder to the presidential debate?\n",
      "\n",
      "Because he heard the stakes were high!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"object\": \"Joe Biden\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38114568",
   "metadata": {},
   "source": [
    "### 4- ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad6a3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template =  \"You are a helpful assistant for translation\\\n",
    " {input_language} to {output_language}.\"\n",
    "\n",
    "human_template = \"{text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8884851",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6803c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant for translation English to Turkish.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What are you seeking?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format_messages(\n",
    "    input_language = \"English\",\n",
    "    output_language = \"Turkish\",\n",
    "    text = \"What are you seeking?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7969cd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ne arÄ±yorsunuz?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = chat_prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"input_language\": \"English\",\n",
    "    \"output_language\": \"Turkish\",\n",
    "    \"text\": \"What are you seeking?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad03d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
