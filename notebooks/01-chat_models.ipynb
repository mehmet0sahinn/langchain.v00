{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20ea403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv; load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd0976",
   "metadata": {},
   "source": [
    "### 1- Chat with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2541e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature = 0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207ec8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Adana is Adana.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 14, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BpY1Pq5bBV8Yz840Jh6TFqPA4SzAA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0f8e9428-27c2-4527-82a6-75adde065b93-0', usage_metadata={'input_tokens': 14, 'output_tokens': 9, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What is the capital of Adana\"\n",
    "llm.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e5930",
   "metadata": {},
   "source": [
    "### 2- Chat with HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6196341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scald\\Downloads\\AI PROJECTS\\4- LangChain\\2-pratik\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "base_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",    \n",
    "    task=\"conversational\",                          # critical change\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "chat_llm = ChatHuggingFace(llm=base_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65444fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I think AI can be a powerful tool for solving complex problems, streamlining workflows, and achieving automation. However, it's important to use AI responsibly and with transparency, and to consider its ethical implications. Some concerns include job displacement, data privacy, and potential misuse.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 34, 'total_tokens': 105}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.3', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='run--ed41bd54-cc80-4012-aecd-967657237048-0' usage_metadata={'input_tokens': 34, 'output_tokens': 71, 'total_tokens': 105}\n"
     ]
    }
   ],
   "source": [
    "print(chat_llm.invoke(\"What do you think about AI?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134691f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İstediğiniz yerde fikirinizle modülü yaratmak istiyorum.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "msgs = [\n",
    "    SystemMessage(content=\"Yardımcı bir asistansın.\"),\n",
    "    HumanMessage(content=\"What are you seeking?\")\n",
    "]\n",
    "print(chat_llm.invoke(msgs).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878a0c0",
   "metadata": {},
   "source": [
    "Note: There is a problem text-generation with huggingface api inference.\n",
    "They dropped support for HuggingFaceHub from previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83482e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
